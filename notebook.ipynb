{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f918a65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import undetected_chromedriver as uc\n",
    "import lxml\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b08d292",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--ignore-certificate-errors')\n",
    "options.add_argument('--ignore-ssl-errors')\n",
    "# options.add_argument('--disable-images')\n",
    "# options.add_argument('--disable-javascript')\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "prefs = {\n",
    "    \"profile.managed_default_content_settings.images\": 2,\n",
    "    # \"profile.managed_default_content_settings.javascript\": 1  # Still not advisable\n",
    "}\n",
    "options.add_experimental_option(\"prefs\", prefs)\n",
    "options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.5845.188 Safari/537.36')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2622b9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver = uc.Chrome(options=options)\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "driver.get(\"https://www.nigelfrank.com/microsoft-jobs\")\n",
    "     # Wait for job listings to load\n",
    "WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"__next\"]/div/div[1]/div[2]/div/div[2]')))\n",
    "soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "# print('sp', soup)\n",
    "driver.quit()\n",
    "job_list = soup.find_all('div', class_=\"sc-AykKG sc-fzXfQW BqA-ds\")\n",
    "\n",
    "print(\"len\", len(job_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8546963",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nigelfrank_scraper(url):\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    # driver.get(\"https://www.nigelfrank.com/microsoft-jobs\")\n",
    "    try:\n",
    "    \n",
    "        driver.get(url)\n",
    "            # Wait for job listings to load\n",
    "        WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"__next\"]/div/div[1]/div[2]/div/div[2]')))\n",
    "        soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "        # driver.quit()\n",
    "        job_list = soup.find_all('div', class_=\"sc-AykKG sc-fzXfQW BqA-ds\")\n",
    "        print(f\"{url} Jobs found\", len(job_list))\n",
    "        job_data = []\n",
    "        \n",
    "        for job in job_list:\n",
    "            link_em = job.find('a',class_=\"sc-AykKE fwNdOp\")\n",
    "            # print(\"link_em\", link_em)\n",
    "            job_url = \"https://www.nigelfrank.com/\" + link_em['href'] if link_em and link_em.get('href') else None\n",
    "            job_id = job_url.split(\"/\")[-2] if job_url else None\n",
    "            title_em = job.find('h3', class_=\"sc-AykKD fECRJb jobTitle\")\n",
    "            title = title_em.text.strip() if title_em else None\n",
    "            location_em = job.find('p', class_=\"location\")\n",
    "            location = location_em.text.strip() if location_em else None\n",
    "            info_list_em = job.find('ul', class_=\"particulars\" )\n",
    "            info_em = info_list_em.find_all('li')\n",
    "            salary = role_type = level = None\n",
    "            # salary = info_em[0].text.strip() if info_em else None\n",
    "            # role_type = info_em[1].text.strip() if info_em else None\n",
    "            # level = info_em[2].text.split(\":\")[-1].strip() if info_em else None\n",
    "            if info_list_em:\n",
    "                    info_em = info_list_em.find_all('li')\n",
    "                    if len(info_em) > 0: salary = info_em[0].get_text(strip=True)\n",
    "                    if len(info_em) > 1: role_type = info_em[1].get_text(strip=True)\n",
    "                    if len(info_em) > 2: level = info_em[2].get_text(strip=True).split(\":\")[-1].strip()\n",
    "\n",
    "            job_desc_em = job.find(\"div\", class_=\"jobDescription\")\n",
    "            job_desc_div = job_desc_em.find(\"div\")\n",
    "            # job_desc_em_br = job_desc_em.find_all(\"br\")\n",
    "            description = job_desc_div.text if job_desc_div else ''\n",
    "            print('job_url', job_id)\n",
    "            data ={\n",
    "                \"title\":title,\n",
    "                \"job_id\": job_id,\n",
    "                \"job_url\":job_url,\n",
    "                \"location\":location,\n",
    "                \"salary\":salary,\n",
    "                \"role_type\":role_type,\n",
    "                \"level\":level,\n",
    "                \"description\": description\n",
    "            }\n",
    "            \n",
    "            job_data.append(data)\n",
    "            \n",
    "        return job_data    \n",
    "    except Exception as e:\n",
    "        print(f\"Error scarping {url}:{e}\")\n",
    "        return []\n",
    "    finally:\n",
    "        driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8d378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# urls base on thr page (1-145)\n",
    "\n",
    "start_urls = [\n",
    "    f\"https://www.nigelfrank.com/microsoft-jobs?newJobs=&keyword=&location=&jobType=both&page={i}&remote=&security=&salaryFrom=&salaryTo=&salaryCurrency=&segment=&product=\"\n",
    "    for i in range(1, 148)\n",
    "]\n",
    "final_data = []\n",
    "for url in start_urls:\n",
    "    try:\n",
    "\n",
    "        result = nigelfrank_scraper(url)\n",
    "        final_data.extend(result)\n",
    "        time.sleep(1)  # wait abit for for the next request\n",
    "    except Exception as e:\n",
    "        print(\"here error:\", e)\n",
    "    finally:\n",
    "        print(\"final data len\", len(final_data))\n",
    "        df = pd.DataFrame(final_data)\n",
    "        df.to_csv(\"nigelfranck.csv\")\n",
    "        print(f\"saved {len(df)} number of jobs\")\n",
    "\n",
    "# https://www.nigelfrank.com/microsoft-jobs?newJobs=&keyword=&location=&jobType=both&page=3&remote=&security=&salaryFrom=&salaryTo=&salaryCurrency=&segment=&product="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
